{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotional Detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9X_QGldNOH"
      },
      "source": [
        "!rm -R AML2021\n",
        "!git clone https://github.com/sleuoth-hof/AML2021.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM7bxhw6dbnM"
      },
      "source": [
        "_file_dir = './AML2021/emotion-recognition/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcffMikhqGj"
      },
      "source": [
        "_kafka_sever = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3hEO3o9295N"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class FacialExpressionModel(object):\n",
        "\n",
        "    EMOTIONS_LIST = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\",\"Sad\",\"Surprised\"]\n",
        "    \n",
        "    def __init__(self, model_json_file, model_weights_file):\n",
        "        with open(model_json_file,\"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            self.loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "        self.loaded_model.load_weights(model_weights_file)\n",
        "        self.loaded_model.make_predict_function()\n",
        "\n",
        "    def predict_emotion(self, img):\n",
        "        self.preds = self.loaded_model.predict(img)\n",
        "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYSOKQEn2wRF"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "facec = cv2.CascadeClassifier(_file_dir + 'haarcascade_frontalface_default.xml')\n",
        "model = FacialExpressionModel(_file_dir + \"model.json\", _file_dir + \"model_weights.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efD-0fgleuPL"
      },
      "source": [
        "!pip install kafka-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZLpL-CuevMU"
      },
      "source": [
        "from kafka import KafkaConsumer\n",
        "from kafka import KafkaProducer\n",
        "import json\n",
        "import base64\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "producer = KafkaProducer(bootstrap_servers=_kafka_sever)\n",
        "\n",
        "consumer = KafkaConsumer('faces_found_detail', bootstrap_servers=[_kafka_sever], auto_offset_reset='latest')\n",
        "\n",
        "\n",
        "for message in consumer:\n",
        "\n",
        " print(message.value)\n",
        "\n",
        " data = json.loads(message.value)\n",
        "\n",
        " img = base64.b64decode(data[\"image_cut_out\"]); \n",
        "\n",
        " \n",
        " npimg = np.fromstring(img, dtype=np.uint8); \n",
        " fr = cv2.imdecode(npimg, 1)\n",
        "\n",
        " cv2_imshow(fr)\n",
        "\n",
        " gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        " (x,y,w,h) = data[\"object_box\"]\n",
        "\n",
        " #fc = gray_fr[y:y+h, x:x+w]\n",
        "\n",
        " cv2_imshow(gray_fr)\n",
        "\n",
        " roi = cv2.resize(gray_fr, (48, 48))\n",
        " pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
        "\n",
        " print(pred)\n",
        "\n",
        " j = {\n",
        "     \"id\": data[\"id\"],\n",
        "     \"face_nr\": data[\"face_nr\"],\n",
        "     \"box\": [x, y, w, h],\n",
        "     \"emotion\": pred,\n",
        "     \"image_cut_out\": data[\"image_cut_out\"] \n",
        " }\n",
        "\n",
        " print(str.encode(json.dumps(j)))\n",
        "\n",
        " producer.send('gui-response_emotion', str.encode(json.dumps(j)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}